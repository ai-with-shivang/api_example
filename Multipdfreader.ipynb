{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cbd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install pdfplumber langchain faiss-cpu sentence-transformers ollama langchain-text-splitters langchain-community\n",
    "\n",
    "import subprocess\n",
    "import pdfplumber\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b96710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Step 1: Extract text from PDFs\n",
    "# -------------------------------\n",
    "def extract_pdf_text(pdf_path):\n",
    "    \"\"\"Extracts text from a single PDF file with page previews.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                print(f\"\\n--- Page {i+1} Preview ({pdf_path}) ---\")\n",
    "                print(page_text[:200], \"...\")\n",
    "                text += page_text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Step 2: Build vectorstore from multiple PDFs\n",
    "# -------------------------------\n",
    "def build_vectorstore_from_pdfs(pdf_paths, verbose=True):\n",
    "    \"\"\"Builds a single FAISS vectorstore from multiple PDFs with debug prints.\"\"\"\n",
    "    all_chunks = []\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "    # Loop through each PDF\n",
    "    for path in pdf_paths:\n",
    "        text = extract_pdf_text(path)\n",
    "        chunks = splitter.split_text(text)\n",
    "        print(f\"\\n✅ {path} → {len(chunks)} chunks created\")\n",
    "\n",
    "        # Print every chunk if verbose=True\n",
    "        if verbose:\n",
    "            for i, ch in enumerate(chunks):\n",
    "                print(f\"\\n--- Chunk {i+1} ---\")\n",
    "                print(f\"Text Preview: {ch[:200]}...\")\n",
    "                print(f\"Token count (approx): {len(ch.split())}\")\n",
    "\n",
    "                # Embed this chunk directly for preview\n",
    "                embeddings_preview = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "                emb = embeddings_preview.embed_query(ch)\n",
    "                print(f\"Embedding length: {len(emb)}\")\n",
    "                print(f\"First 10 values: {emb[:10]}\")\n",
    "\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    print(f\"\\n✅ Total chunks across PDFs: {len(all_chunks)}\")\n",
    "\n",
    "    # Build FAISS vectorstore\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_texts(all_chunks, embeddings)\n",
    "    print(\"\\n✅ Vectorstore built successfully with FAISS.\")\n",
    "    print(f\"--- Vectorstore Info ---\\nTotal vectors: {vectorstore.index.ntotal}\")\n",
    "    print(f\"Embedding dimension: {vectorstore.index.d}\")\n",
    "    print(f\"Docstore IDs: {list(vectorstore.docstore._dict.keys())[:5]} ...\")\n",
    "\n",
    "    # Show embedding preview for first vector\n",
    "    emb0 = vectorstore.index.reconstruct(0)\n",
    "    print(f\"\\n--- First Embedding Vector Preview ---\\nLength: {len(emb0)}\\nFirst 20 values: {emb0[:20]}\")\n",
    "\n",
    "    # Map IDs to text\n",
    "    print(\"\\n--- ID → Text → Embedding Mapping ---\")\n",
    "    for pos, doc_id in list(vectorstore.index_to_docstore_id.items())[:5]:\n",
    "        doc = vectorstore.docstore._dict.get(doc_id)\n",
    "        emb = vectorstore.index.reconstruct(pos)\n",
    "        print(f\"Vector Pos: {pos}\\nID: {doc_id}\\nText Preview: {doc.page_content[:100]}...\\nEmbedding First 10 values: {emb[:10]}\\n\")\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Step 3: Ask question across PDFs\n",
    "# -------------------------------\n",
    "def ask_question(vectorstore, query, k=3):\n",
    "    \"\"\"Searches across all PDFs in the vectorstore and returns an answer with debug prints.\"\"\"\n",
    "    docs = vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "    print(\"\\n--- Retrieved Chunks for Query ---\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\nChunk {i+1}:\\n{doc.page_content}\\n\")\n",
    "\n",
    "    context = \"\\n\".join([d.page_content for d in docs])\n",
    "    prompt = f\"Answer the question based on the PDFs:\\n\\n{context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", \"llama3\"],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        encoding=\"utf-8\",\n",
    "        errors=\"replace\",\n",
    "        capture_output=True\n",
    "    )\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Example usage\n",
    "# -------------------------------\n",
    "pdf_paths = [\n",
    "    r\"C:\\Users\\2shiv\\Downloads\\Shivang_Soni_Enhanced_CV.pdf\",\n",
    "    r\"C:\\Users\\2shiv\\Downloads\\Research_Paper_On_Artificial_Intelligence_And_Its.pdf\"\n",
    "]\n",
    "\n",
    "vectorstore = build_vectorstore_from_pdfs(pdf_paths, verbose=True)\n",
    "\n",
    "question = \"Summarize Shivang Soni's skills and the main AI research topics.\"\n",
    "answer = ask_question(vectorstore, question)\n",
    "\n",
    "print(\"\\n--- Final Answer from Ollama ---\\n\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-reader (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
